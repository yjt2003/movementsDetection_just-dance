# detector/pose_detector.py
# æ ¸å¿ƒå§¿æ€æ£€æµ‹æ¨¡å—

import cv2
import numpy as np
import mediapipe as mp
import time
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# =============================================================================
# 1. æ•°æ®ç»“æ„å®šä¹‰
# =============================================================================

class DetectorType(Enum):
    """æ£€æµ‹å™¨ç±»å‹æšä¸¾"""
    MEDIAPIPE = "mediapipe"
    YOLOV8 = "yolov8"
    HYBRID = "hybrid"


@dataclass
class Keypoint:
    """å…³é”®ç‚¹æ•°æ®ç»“æ„"""
    x: float
    y: float
    confidence: float
    visible: bool = True
    predicted: bool = False  # æ˜¯å¦ä¸ºé¢„æµ‹ç‚¹

    def to_dict(self) -> Dict[str, Any]:
        return {
            'x': self.x,
            'y': self.y,
            'confidence': self.confidence,
            'visible': self.visible,
            'predicted': self.predicted
        }


@dataclass
class Hand:
    """
    æ‰‹åŠ¿å…³é”®ç‚¹æ•°æ®ç»“æ„
    """
    handedness: str  # 'Left' or 'Right'
    keypoints: List[Keypoint]
    confidence: float

# ä¿®æ”¹Personï¼Œå¢åŠ handså­—æ®µ
@dataclass
class Person:
    id: int
    keypoints: List[Keypoint]
    bbox: Tuple[float, float, float, float]
    confidence: float
    hands: List[Hand]  # æ–°å¢
    timestamp: float
    detector_type: str

    def to_dict(self) -> Dict[str, Any]:
        return {
            'id': self.id,
            'keypoints': [kp.to_dict() for kp in self.keypoints],
            'bbox': list(self.bbox),
            'confidence': self.confidence,
            'hands': [
                {
                    'handedness': hand.handedness,
                    'confidence': hand.confidence,
                    'keypoints': [kp.to_dict() for kp in hand.keypoints]
                } for hand in self.hands
            ],
            'timestamp': self.timestamp,
            'detector_type': self.detector_type
        }


# =============================================================================
# 2. åŸºç¡€æ£€æµ‹å™¨æ¥å£
# =============================================================================

class BasePoseDetector:
    """å§¿æ€æ£€æµ‹å™¨åŸºç±»"""

    def __init__(self, confidence_threshold: float = 0.5):
        self.confidence_threshold = confidence_threshold
        self.detection_count = 0

    def detect(self, frame: np.ndarray) -> List[Person]:
        """æ£€æµ‹å›¾åƒä¸­çš„äººå‘˜å§¿æ€"""
        raise NotImplementedError

    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        raise NotImplementedError

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        pass


# =============================================================================
# 3. MediaPipeæ£€æµ‹å™¨å®ç°
# =============================================================================

class MediaPipeDetector(BasePoseDetector):
    """MediaPipeå…¨èº«+æ‰‹åŠ¿æ£€æµ‹å™¨"""

    def __init__(self, confidence_threshold: float = 0.5, model_complexity: int = 1):
        super().__init__(confidence_threshold)
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=model_complexity,
            enable_segmentation=False,
            min_detection_confidence=confidence_threshold,
            min_tracking_confidence=confidence_threshold
        )
        self.mp_drawing = mp.solutions.drawing_utils
        # æ–°å¢æ‰‹åŠ¿æ£€æµ‹å™¨
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            min_detection_confidence=confidence_threshold,
            min_tracking_confidence=confidence_threshold
        )
        logger.info(f"âœ… MediaPipeå…¨èº«+æ‰‹åŠ¿æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ (confidence={confidence_threshold})")

    def detect(self, frame: np.ndarray) -> List[Person]:
        try:
            self.detection_count += 1
            height, width = frame.shape[:2]
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.pose.process(rgb_frame)
            detected_persons = []
            if results.pose_landmarks:
                keypoints = []
                for i, landmark in enumerate(results.pose_landmarks.landmark):
                    kp = Keypoint(
                        x=landmark.x * width,
                        y=landmark.y * height,
                        confidence=landmark.visibility,
                        visible=landmark.visibility > self.confidence_threshold
                    )
                    keypoints.append(kp)
                bbox = self._calculate_bbox(keypoints, width, height)
                # æ‰‹åŠ¿æ£€æµ‹ï¼ˆå¯¹bboxåŒºåŸŸè£å‰ªï¼‰
                x1, y1, x2, y2 = map(int, bbox)
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(width, x2), min(height, y2)
                person_img = rgb_frame[y1:y2, x1:x2]
                hands = self._detect_hands(person_img, x1, y1)
                person = Person(
                    id=0,
                    keypoints=keypoints,
                    bbox=bbox,
                    confidence=np.mean([kp.confidence for kp in keypoints if kp.visible]),
                    hands=hands,
                    timestamp=time.time(),
                    detector_type="mediapipe"
                )
                detected_persons.append(person)
                logger.debug(f"MediaPipeæ£€æµ‹åˆ°1ä¸ªäººï¼Œ{len([kp for kp in keypoints if kp.visible])}ä¸ªæœ‰æ•ˆå…³é”®ç‚¹ï¼Œ{len(hands)}åªæ‰‹")
            return detected_persons
        except Exception as e:
            logger.error(f"MediaPipeæ£€æµ‹é”™è¯¯: {e}")
            return []

    def _calculate_bbox(self, keypoints: List[Keypoint], width: int, height: int) -> Tuple[float, float, float, float]:
        """è®¡ç®—è¾¹ç•Œæ¡†"""
        valid_points = [(kp.x, kp.y) for kp in keypoints if kp.visible]

        if not valid_points:
            return (0, 0, width, height)

        xs, ys = zip(*valid_points)
        x1, y1 = max(0, min(xs) - 20), max(0, min(ys) - 20)
        x2, y2 = min(width, max(xs) + 20), min(height, max(ys) + 20)

        return (x1, y1, x2, y2)

    def _detect_hands(self, img: np.ndarray, x_offset: int, y_offset: int) -> List[Hand]:
        """
        å¯¹è¾“å…¥å›¾åƒæ£€æµ‹æ‰‹åŠ¿ï¼Œå¹¶å°†å…³é”®ç‚¹åæ ‡æ˜ å°„å›åŸå›¾
        """
        hands_result = self.hands.process(img)
        hands = []
        if hands_result.multi_hand_landmarks and hands_result.multi_handedness:
            for hand_landmarks, handedness in zip(hands_result.multi_hand_landmarks, hands_result.multi_handedness):
                kp_list = []
                for lm in hand_landmarks.landmark:
                    kp = Keypoint(
                        x=lm.x * img.shape[1] + x_offset,
                        y=lm.y * img.shape[0] + y_offset,
                        confidence=lm.z,  # handsæ²¡æœ‰visibilityï¼Œzå¯ç”¨ä½œç½®ä¿¡åº¦å‚è€ƒ
                        visible=True
                    )
                    kp_list.append(kp)
                hand = Hand(
                    handedness=handedness.classification[0].label,
                    keypoints=kp_list,
                    confidence=handedness.classification[0].score
                )
                hands.append(hand)
        return hands

    def get_model_info(self) -> Dict[str, Any]:
        return {
            "name": "MediaPipe Pose",
            "type": DetectorType.MEDIAPIPE.value,
            "keypoints": 33,
            "real_time": True,
            "detection_count": self.detection_count
        }

    def cleanup(self):
        if hasattr(self, 'pose'):
            self.pose.close()
        if hasattr(self, 'hands'):
            self.hands.close()
        logger.info("MediaPipeèµ„æºå·²æ¸…ç†")


# =============================================================================
# 4. YOLOv8æ£€æµ‹å™¨å®ç° (å¯é€‰)
# =============================================================================

class YOLOv8Detector(BasePoseDetector):
    """YOLOv8å§¿æ€æ£€æµ‹å™¨ (å¯é€‰ç»„ä»¶)"""

    def __init__(self, model_path: str = "yolov8n-pose.pt", confidence_threshold: float = 0.3):
        super().__init__(confidence_threshold)

        try:
            from ultralytics import YOLO
            self.model = YOLO(model_path)
            self.available = True
            logger.info(f"âœ… YOLOv8æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ (model={model_path})")
        except ImportError:
            logger.warning("âš ï¸  YOLOv8ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install ultralytics")
            self.available = False
        except Exception as e:
            logger.error(f"âŒ YOLOv8åˆå§‹åŒ–å¤±è´¥: {e}")
            self.available = False

    def detect(self, frame: np.ndarray) -> List[Person]:
        """YOLOv8å§¿æ€æ£€æµ‹"""
        if not self.available:
            return []

        try:
            self.detection_count += 1
            results = self.model(frame, conf=self.confidence_threshold, verbose=False)

            detected_persons = []

            for result in results:
                if result.keypoints is not None:
                    keypoints_data = result.keypoints.xyn.cpu().numpy()
                    boxes = result.boxes.xyxy.cpu().numpy() if result.boxes else None

                    for i, person_kpts in enumerate(keypoints_data):
                        keypoints = []

                        # å¤„ç†17ä¸ªCOCOå…³é”®ç‚¹
                        for j, (x, y) in enumerate(person_kpts):
                            kp = Keypoint(
                                x=x * frame.shape[1],
                                y=y * frame.shape[0],
                                confidence=0.8,  # YOLOv8æ²¡æœ‰ç›´æ¥çš„å…³é”®ç‚¹ç½®ä¿¡åº¦
                                visible=x > 0 and y > 0
                            )
                            keypoints.append(kp)

                        # è¾¹ç•Œæ¡†
                        if boxes is not None and i < len(boxes):
                            bbox = tuple(boxes[i])
                        else:
                            bbox = self._calculate_bbox_yolo(keypoints, frame.shape[1], frame.shape[0])

                        person = Person(
                            id=i,
                            keypoints=keypoints,
                            bbox=bbox,
                            confidence=0.8,
                            timestamp=time.time(),
                            detector_type="yolov8"
                        )

                        detected_persons.append(person)

            logger.debug(f"YOLOv8æ£€æµ‹åˆ°{len(detected_persons)}ä¸ªäºº")
            return detected_persons

        except Exception as e:
            logger.error(f"YOLOv8æ£€æµ‹é”™è¯¯: {e}")
            return []

    def _calculate_bbox_yolo(self, keypoints: List[Keypoint], width: int, height: int) -> Tuple[
        float, float, float, float]:
        """ä¸ºYOLOv8è®¡ç®—è¾¹ç•Œæ¡†"""
        valid_points = [(kp.x, kp.y) for kp in keypoints if kp.visible]

        if not valid_points:
            return (0, 0, width, height)

        xs, ys = zip(*valid_points)
        return (min(xs), min(ys), max(xs), max(ys))

    def get_model_info(self) -> Dict[str, Any]:
        return {
            "name": "YOLOv8 Pose",
            "type": DetectorType.YOLOV8.value,
            "keypoints": 17,
            "real_time": True,
            "available": self.available,
            "detection_count": self.detection_count
        }


# =============================================================================
# 5. æ··åˆæ£€æµ‹å™¨ (æ™ºèƒ½åˆ‡æ¢)
# =============================================================================

class HybridDetector(BasePoseDetector):
    """æ··åˆæ£€æµ‹å™¨ - æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æ¨¡å‹"""

    def __init__(self, confidence_threshold: float = 0.5):
        super().__init__(confidence_threshold)

        # åˆå§‹åŒ–ä¸¤ä¸ªæ£€æµ‹å™¨
        self.mediapipe = MediaPipeDetector(confidence_threshold)
        self.yolov8 = YOLOv8Detector(confidence_threshold=confidence_threshold)

        # å½“å‰ä½¿ç”¨çš„æ£€æµ‹å™¨
        self.current_detector = self.mediapipe
        self.switch_threshold = 0.7  # åˆ‡æ¢é˜ˆå€¼

        logger.info("âœ… æ··åˆæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")

    def detect(self, frame: np.ndarray) -> List[Person]:
        """æ™ºèƒ½æ£€æµ‹"""
        try:
            # åˆ†æåœºæ™¯é€‰æ‹©æœ€ä¼˜æ£€æµ‹å™¨
            optimal_detector = self._select_optimal_detector(frame)

            if optimal_detector != self.current_detector:
                self.current_detector = optimal_detector
                logger.info(f"ğŸ”„ æ£€æµ‹å™¨åˆ‡æ¢åˆ°: {self.current_detector.get_model_info()['name']}")

            return self.current_detector.detect(frame)

        except Exception as e:
            logger.error(f"æ··åˆæ£€æµ‹å™¨é”™è¯¯: {e}")
            # å›é€€åˆ°MediaPipe
            return self.mediapipe.detect(frame)

    def _select_optimal_detector(self, frame: np.ndarray) -> BasePoseDetector:
        """æ ¹æ®åœºæ™¯é€‰æ‹©æœ€ä¼˜æ£€æµ‹å™¨"""
        # ç®€å•çš„å¯å‘å¼è§„åˆ™
        height, width = frame.shape[:2]

        # è®¡ç®—äº®åº¦
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        brightness = np.mean(gray) / 255.0

        # é€‰æ‹©ç­–ç•¥
        if brightness < 0.3:  # ä½å…‰ç¯å¢ƒ
            return self.mediapipe  # MediaPipeåœ¨ä½å…‰ä¸‹è¡¨ç°æ›´å¥½
        elif width * height > 1920 * 1080:  # é«˜åˆ†è¾¨ç‡
            return self.yolov8 if self.yolov8.available else self.mediapipe
        else:
            return self.mediapipe  # é»˜è®¤ä½¿ç”¨MediaPipe

    def get_model_info(self) -> Dict[str, Any]:
        return {
            "name": "Hybrid Detector",
            "type": DetectorType.HYBRID.value,
            "current": self.current_detector.get_model_info(),
            "mediapipe_available": True,
            "yolov8_available": self.yolov8.available,
            "detection_count": self.detection_count
        }

    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰æ£€æµ‹å™¨èµ„æº"""
        self.mediapipe.cleanup()
        if self.yolov8.available:
            self.yolov8.cleanup()


# =============================================================================
# 6. æ£€æµ‹å™¨å·¥å‚
# =============================================================================

class DetectorFactory:
    """æ£€æµ‹å™¨å·¥å‚ç±»"""

    @staticmethod
    def create_detector(detector_type: DetectorType, **kwargs) -> BasePoseDetector:
        """åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹"""
        try:
            if detector_type == DetectorType.MEDIAPIPE:
                return MediaPipeDetector(**kwargs)
            elif detector_type == DetectorType.YOLOV8:
                return YOLOv8Detector(**kwargs)
            elif detector_type == DetectorType.HYBRID:
                return HybridDetector(**kwargs)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ£€æµ‹å™¨ç±»å‹: {detector_type}")

        except Exception as e:
            logger.error(f"åˆ›å»ºæ£€æµ‹å™¨å¤±è´¥: {e}")
            # å›é€€åˆ°MediaPipe
            logger.info("å›é€€åˆ°MediaPipeæ£€æµ‹å™¨")
            return MediaPipeDetector(**kwargs)

    @staticmethod
    def get_available_detectors() -> List[DetectorType]:
        """è·å–å¯ç”¨çš„æ£€æµ‹å™¨ç±»å‹"""
        available = [DetectorType.MEDIAPIPE]  # MediaPipeæ€»æ˜¯å¯ç”¨

        # æ£€æŸ¥YOLOv8æ˜¯å¦å¯ç”¨
        try:
            import ultralytics
            available.append(DetectorType.YOLOV8)
            available.append(DetectorType.HYBRID)
        except ImportError:
            pass

        return available


# =============================================================================
# 7. ä¸»æ£€æµ‹ç®¡ç†å™¨
# =============================================================================

class PoseDetectionManager:
    """å§¿æ€æ£€æµ‹ç®¡ç†å™¨ - ç»Ÿä¸€æ¥å£"""

    def __init__(self, detector_type: DetectorType = DetectorType.MEDIAPIPE,
                 confidence_threshold: float = 0.5):

        self.detector = DetectorFactory.create_detector(detector_type,
                                                        confidence_threshold=confidence_threshold)
        self.detection_stats = {
            'total_detections': 0,
            'successful_detections': 0,
            'average_persons_per_frame': 0,
            'start_time': time.time()
        }

        logger.info(f"ğŸš€ å§¿æ€æ£€æµ‹ç®¡ç†å™¨å¯åŠ¨: {self.detector.get_model_info()['name']}")

    def detect_poses(self, frame: np.ndarray) -> Tuple[List[Person], Dict[str, Any]]:
        """æ£€æµ‹å§¿æ€å¹¶è¿”å›ç»Ÿè®¡ä¿¡æ¯"""
        start_time = time.time()

        # æ‰§è¡Œæ£€æµ‹
        persons = self.detector.detect(frame)

        # æ›´æ–°ç»Ÿè®¡
        self._update_stats(persons, time.time() - start_time)

        # æ£€æµ‹ä¿¡æ¯
        detection_info = {
            'persons_count': len(persons),
            'processing_time_ms': (time.time() - start_time) * 1000,
            'detector_info': self.detector.get_model_info(),
            'frame_size': frame.shape[:2]
        }

        return persons, detection_info

    def _update_stats(self, persons: List[Person], processing_time: float):
        """æ›´æ–°æ£€æµ‹ç»Ÿè®¡"""
        self.detection_stats['total_detections'] += 1
        if persons:
            self.detection_stats['successful_detections'] += 1

        # è®¡ç®—å¹³å‡äººæ•°
        total_persons = sum(len(persons) for persons in [persons])  # ç®€åŒ–ç‰ˆæœ¬
        self.detection_stats['average_persons_per_frame'] = (
                total_persons / self.detection_stats['total_detections']
        )

    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        runtime = time.time() - self.detection_stats['start_time']

        return {
            **self.detection_stats,
            'runtime_seconds': runtime,
            'detection_rate': self.detection_stats['total_detections'] / runtime if runtime > 0 else 0,
            'success_rate': (self.detection_stats['successful_detections'] /
                             max(self.detection_stats['total_detections'], 1)) * 100,
            'detector_info': self.detector.get_model_info()
        }

    def switch_detector(self, new_detector_type: DetectorType):
        """åˆ‡æ¢æ£€æµ‹å™¨"""
        try:
            old_detector = self.detector
            self.detector = DetectorFactory.create_detector(new_detector_type)
            old_detector.cleanup()
            logger.info(f"ğŸ”„ æ£€æµ‹å™¨å·²åˆ‡æ¢åˆ°: {self.detector.get_model_info()['name']}")
        except Exception as e:
            logger.error(f"åˆ‡æ¢æ£€æµ‹å™¨å¤±è´¥: {e}")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.detector:
            self.detector.cleanup()
        logger.info("å§¿æ€æ£€æµ‹ç®¡ç†å™¨å·²æ¸…ç†")


# =============================================================================
# 8. ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
# =============================================================================

def test_pose_detector():
    """æµ‹è¯•å§¿æ€æ£€æµ‹å™¨"""

    print("ğŸ§ª å¼€å§‹æµ‹è¯•å§¿æ€æ£€æµ‹å™¨...")

    # åˆ›å»ºæ£€æµ‹ç®¡ç†å™¨
    manager = PoseDetectionManager(DetectorType.MEDIAPIPE)

    # æ¨¡æ‹Ÿæ£€æµ‹
    test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)

    try:
        persons, detection_info = manager.detect_poses(test_frame)

        print(f"âœ… æ£€æµ‹å®Œæˆ:")
        print(f"   æ£€æµ‹åˆ°äººæ•°: {detection_info['persons_count']}")
        print(f"   å¤„ç†æ—¶é—´: {detection_info['processing_time_ms']:.2f}ms")
        print(f"   æ£€æµ‹å™¨: {detection_info['detector_info']['name']}")

        # æ€§èƒ½ç»Ÿè®¡
        stats = manager.get_performance_stats()
        print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"   æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        print(f"   æ£€æµ‹é¢‘ç‡: {stats['detection_rate']:.1f} FPS")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

    finally:
        manager.cleanup()


# =============================================================================
# 9.
# =============================================================================


if __name__ == "__main__":
    test_pose_detector()