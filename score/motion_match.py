import numpy as np
import cv2
import os
import mediapipe as mp

def extract_ref_frames(beat_frame_indices: np.ndarray, video_path: str, output_dir="ref_frames"):
    """
    æ ¹æ®èŠ‚æ‹å¸§å·ï¼ˆnp.ndarrayï¼‰æå–å‚è€ƒè§†é¢‘ä¸­çš„å›¾åƒå¸§ã€‚
    :param beat_frame_indices: ndarrayï¼Œæ¯ä¸ªèŠ‚æ‹å¯¹åº”çš„å¸§å·ï¼ˆæ•´æ•°ï¼‰
    :param video_path: è§†é¢‘è·¯å¾„
    :param output_dir: ä¿å­˜å¸§å›¾åƒçš„æ–‡ä»¶å¤¹
    :return: list[dict]ï¼Œæ¯å¸§åŒ…å« frame_path å’Œ frame_index
    """
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)

    ref_frames = []

    for i, frame_idx in enumerate(beat_frame_indices):
        frame_idx = int(frame_idx)  # ä¿è¯ä¸ºæ•´æ•°
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if ret:
            filename = os.path.join(output_dir, f"ref_{i:03d}.jpg")
            cv2.imwrite(filename, frame)
            print(f"âœ… Saved {filename} (frame {frame_idx})")
            ref_frames.append({
                "frame_path": filename,
                "index": frame_idx
            })
        else:
            print(f"âš ï¸ Failed to read frame {frame_idx}")

    cap.release()
    return ref_frames


def extract_user_frames(video_path: str, output_dir="user_frames"):
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)

    frame_list = []
    frame_idx = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        time_sec = frame_idx / fps
        filename = f"{output_dir}/user_{frame_idx:04d}.jpg"
        cv2.imwrite(filename, frame)

        frame_list.append({
            "frame_path": filename,
            "time": time_sec,
            "index": frame_idx
        })

        frame_idx += 1

    cap.release()
    return frame_list  # åˆ—è¡¨ä¸­åŒ…å«æ¯ä¸€å¸§çš„è·¯å¾„å’Œæ—¶é—´ä¿¡æ¯


def match_user_frames_to_ref(ref_frames, user_frames, fps, pose_similarity):# video vs video
    """
    å¯¹æ¯ä¸ªå‚è€ƒå¸§ï¼Œåœ¨ç”¨æˆ·å¸§åºåˆ—ä¸­å¯»æ‰¾æœ€ç›¸ä¼¼çš„å§¿æ€ï¼Œå¹¶è®¡ç®—æ—¶é—´åå·®ã€‚

    å‚æ•°ï¼š
        ref_frames: List[Dict]ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ {"frame_path": ..., "index": ...}
        user_frames: List[Dict]ï¼Œç»“æ„åŒä¸Š
        fps: floatï¼Œè§†é¢‘å¸§ç‡
        pose_similarity: ä¸€ä¸ªç±»æˆ–å¯¹è±¡ï¼ŒåŒ…å« calculate_pose_similarity æ–¹æ³•

    è¿”å›ï¼š
        List[Dict]ï¼Œæ¯é¡¹åŒ…å«ï¼š
            {
                "ref_index": int,
                "user_index": int,
                "similarity": float,
                "delta_t": float
            }
    """
    results = []

    mp_pose = mp.solutions.pose

    with mp_pose.Pose(static_image_mode=True) as pose_detector:
        for ref in ref_frames:
            ref_img = cv2.imread(ref["frame_path"])
            ref_rgb = cv2.cvtColor(ref_img, cv2.COLOR_BGR2RGB)
            ref_result = pose_detector.process(ref_rgb)
            ref_landmarks = ref_result.pose_landmarks

            best_match = None
            best_similarity = -1

            for user in user_frames:
                user_img = cv2.imread(user["frame_path"])
                user_rgb = cv2.cvtColor(user_img, cv2.COLOR_BGR2RGB)
                user_result = pose_detector.process(user_rgb)
                user_landmarks = user_result.pose_landmarks

                score = pose_similarity.calculate_pose_similarity(ref_landmarks, user_landmarks)
                if score is not None and score > best_similarity:
                    best_similarity = score
                    best_match = user

            if best_match is not None:
                delta_frame = best_match["index"] - ref["index"]
                delta_t = delta_frame / fps
                results.append({
                    "ref_index": ref["index"],
                    "user_index": best_match["index"],
                    "similarity": round(best_similarity, 4),
                    "delta_t": round(delta_t, 4)
                })
            else:
                results.append({
                    "ref_index": ref["index"],
                    "user_index": None,
                    "similarity": None,
                    "delta_t": None
                })

    return results


def match_live_cam_to_ref(ref_frames, fps, pose_similarity):
    """
    ä»å®æ—¶æ‘„åƒå¤´æ•è·å¸§ï¼Œä¸å‚è€ƒå¸§è¿›è¡Œå§¿æ€ç›¸ä¼¼åº¦åŒ¹é…å¹¶è®¡ç®—æ—¶é—´å·®ã€‚
    """
    cap = cv2.VideoCapture(0)
    mp_pose = mp.solutions.pose
    frame_index = 0
    user_time_records = []

    with mp_pose.Pose(static_image_mode=False) as pose_detector:
        while cap.isOpened():
            success, frame = cap.read()
            if not success:
                break

            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result = pose_detector.process(rgb_frame)

            user_landmarks = result.pose_landmarks
            if not user_landmarks:
                frame_index += 1
                continue

            best_ref = None
            best_score = -1
            best_ref_index = -1

            # å¯¹æ‰€æœ‰å‚è€ƒå¸§åšåŒ¹é…
            for ref in ref_frames:
                ref_img = cv2.imread(ref["frame_path"])
                ref_rgb = cv2.cvtColor(ref_img, cv2.COLOR_BGR2RGB)
                ref_result = pose_detector.process(ref_rgb)
                ref_landmarks = ref_result.pose_landmarks

                score = pose_similarity.calculate_pose_similarity(ref_landmarks, user_landmarks)
                if score is not None and score > best_score:
                    best_score = score
                    best_ref = ref
                    best_ref_index = ref["index"]

            # è®°å½•ç”¨æˆ·å¸§ä¸å…¶æœ€ç›¸ä¼¼çš„å‚è€ƒå¸§çš„åŒ¹é…ä¿¡æ¯
            if best_ref is not None:
                delta_frame = frame_index - best_ref_index
                delta_t = delta_frame / fps
                user_time_records.append({
                    "frame_index": frame_index,
                    "ref_index": best_ref_index,
                    "similarity": round(best_score, 4),
                    "delta_t": round(delta_t, 4)
                })
                print(f"ğŸŸ¢ Frame {frame_index} matched Ref {best_ref_index} | "
                      f"Score={best_score:.3f}, Î”t={delta_t:.3f}s")

            frame_index += 1

            # ESC é€€å‡º
            if cv2.waitKey(1) & 0xFF == 27:
                break

    cap.release()
    return user_time_records


def match_motion_to_beats(motion_times, beat_times, threshold=0.4):
    '''
    motion_times: list[float]ï¼Œæ¯ä¸ªåŠ¨ä½œå‘ç”Ÿçš„æ—¶é—´ï¼ˆç§’ï¼‰
    beat_times: list[float]ï¼ŒèŠ‚æ‹é”šç‚¹æ—¶é—´ï¼ˆç§’ï¼‰
    threshold: floatï¼ŒåŒ¹é…é˜ˆå€¼ï¼ˆç§’ï¼‰
    è¿”å›ï¼šåŒ¹é…åˆ†æ•°ï¼ˆ0~1ï¼‰ï¼Œæ¯ä¸ªåŠ¨ä½œä¸æœ€è¿‘èŠ‚æ‹çš„æ—¶é—´å·®
    '''
    if not motion_times or not beat_times:
        return 0.0, []
    deltas = []
    for t in motion_times:
        delta = min([abs(t - b) for b in beat_times])
        deltas.append(delta)
    # ç»Ÿè®¡æœ‰å¤šå°‘åŠ¨ä½œåœ¨é˜ˆå€¼å†…
    match_count = sum([1 for d in deltas if d <= threshold])
    score = match_count / len(motion_times)
    return score, deltas